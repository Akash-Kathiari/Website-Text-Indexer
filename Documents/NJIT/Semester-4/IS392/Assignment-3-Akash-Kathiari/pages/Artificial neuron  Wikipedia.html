<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Artificial neuron - Wikipedia</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Artificial_neuron","wgTitle":"Artificial neuron","wgCurRevisionId":885171186,"wgRevisionId":885171186,"wgArticleId":349771,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 maint: Uses authors parameter","CS1 maint: Uses editors parameter","Wikipedia articles needing clarification from May 2017","Articles to be expanded from May 2017","All articles to be expanded","Articles using small message boxes","Articles to be split from May 2017","All articles to be split","All articles with unsourced statements","Articles with unsourced statements from May 2018","Artificial neural networks","American inventions"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Artificial_neuron","wgRelevantArticleId":349771,"wgRequestId":"XHyBcQpAAEUAAIkFscUAAAAK","wgCSPNonce":false,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgFlaggedRevsParams":{"tags":{}},"wgStableRevisionId":null,"wgCategoryTreePageCategoryOptions":"{\"mode\":0,\"hideprefix\":20,\"showcount\":true,\"namespaces\":false}","wgWikiEditorEnabledModules":[],"wgBetaFeaturesFeatures":[],"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsReferencePreviews":false,"wgPopupsShouldSendModuleToUser":true,"wgPopupsConflictsWithNavPopupGadget":false,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en","usePageImages":true,"usePageDescriptions":true},"wgMFIsPageContentModelEditable":true,"wgMFEnableFontChanger":true,"wgMFDisplayWikibaseDescriptions":{"search":true,"nearby":true,"watchlist":true,"tagline":false},"wgRelatedArticles":null,"wgRelatedArticlesUseCirrusSearch":true,"wgRelatedArticlesOnlyUseCirrusSearch":false,"wgWMESchemaEditAttemptStepOversample":false,"wgPoweredByHHVM":true,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgCentralNoticeCookiesToDelete":[],"wgCentralNoticeCategoriesUsingLegacy":["Fundraising","fundraising"],"wgWikibaseItemId":"Q177058","wgScoreNoteLanguages":{"arabic":"العربية","catalan":"català","deutsch":"Deutsch","english":"English","espanol":"español","italiano":"italiano","nederlands":"Nederlands","norsk":"norsk","portugues":"português","suomi":"suomi","svenska":"svenska","vlaams":"West-Vlams"},"wgScoreDefaultNoteLanguage":"nederlands","wgCentralAuthMobileDomain":false,"wgCodeMirrorEnabled":true,"wgVisualEditorToolbarScrollOffset":0,"wgVisualEditorUnsupportedEditParams":["undo","undoafter","veswitched"],"wgEditSubmitButtonLabelPublish":true,"oresWikiId":"enwiki","oresBaseUrl":"http://ores.discovery.wmnet:8081/","oresApiVersion":3});mw.loader.state({"ext.gadget.charinsert-styles":"ready","ext.globalCssJs.user.styles":"ready","ext.globalCssJs.site.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","ext.globalCssJs.site":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.toc.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","ext.3d.styles":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready"});mw.loader.implement("user.tokens@0tffind",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.startup","mediawiki.page.ready","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.eventlogger","ext.uls.init","ext.uls.compactlinks","ext.uls.interface","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp","skins.vector.js"];mw.loader.load(RLPAGEMODULES);});</script>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=ext.gadget.charinsert-styles&amp;only=styles&amp;skin=vector"/>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.33.0-wmf.19"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Artificial_neuron"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Artificial_neuron&amp;action=edit"/>
<link rel="edit" title="Edit this page" href="/w/index.php?title=Artificial_neuron&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/Artificial_neuron"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/w/load.php?debug=false&amp;lang=en&amp;modules=html5shiv&amp;only=scripts&amp;skin=vector&amp;sync=1"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Artificial_neuron rootpage-Artificial_neuron skin-vector action-view">		<div id="mw-page-base" class="noprint"></div>
		<div id="mw-head-base" class="noprint"></div>
		<div id="content" class="mw-body" role="main">
			<a id="top"></a>
			<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div><div class="mw-indicators mw-body-content">
</div>
<h1 id="firstHeading" class="firstHeading" lang="en">Artificial neuron</h1>			<div id="bodyContent" class="mw-body-content">
				<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>				<div id="contentSub"></div>
				<div id="jump-to-nav"></div>				<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
				<a class="mw-jump-link" href="#p-search">Jump to search</a>
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><p>An <b>artificial neuron</b> is a <a href="/wiki/Function_(mathematics)" title="Function (mathematics)">mathematical function</a> conceived as a <a href="/wiki/Mathematical_model" title="Mathematical model">model</a> of biological <a href="/wiki/Neuron" title="Neuron">neurons</a>, a <a href="/wiki/Neural_network" title="Neural network">neural network</a>. Artificial neurons are elementary units in an <a href="/wiki/Artificial_neural_network" title="Artificial neural network">artificial neural network</a>.  The artificial neuron receives one or more inputs (representing <a href="/wiki/Excitatory_postsynaptic_potential" title="Excitatory postsynaptic potential">excitatory postsynaptic potentials</a> and <a href="/wiki/Inhibitory_postsynaptic_potential" title="Inhibitory postsynaptic potential">inhibitory postsynaptic potentials</a> at neural <a href="/wiki/Dendrite" title="Dendrite">dendrites</a>) and sums them to produce an output (or <span id="activation">activation</span>, representing a neuron's <a href="/wiki/Action_potential" title="Action potential">action potential</a> which is transmitted along its <a href="/wiki/Axon" title="Axon">axon</a>). Usually each input is separately <a href="/wiki/Weighting" title="Weighting">weighted</a>, and the sum is passed through a <a href="/wiki/Non-linear_function" class="mw-redirect" title="Non-linear function">non-linear function</a> known as an <a href="/wiki/Activation_function" title="Activation function">activation function</a> or <a href="/wiki/Transfer_function" title="Transfer function">transfer function</a><sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Please_clarify" title="Wikipedia:Please clarify"><span title="The text near this tag may need clarification or removal of jargon. (May 2017)">clarification needed</span></a></i>&#93;</sup>. The transfer functions usually have a <a href="/wiki/Sigmoid_function" title="Sigmoid function">sigmoid shape</a>, but they may also take the form of other non-linear functions, <a href="/wiki/Piecewise" title="Piecewise">piecewise</a> linear functions, or <a href="#Step_function">step functions</a>. They are also often  <a href="/wiki/Monotonic_function" title="Monotonic function">monotonically increasing</a>, <a href="/wiki/Continuous_function" title="Continuous function">continuous</a>, <a href="/wiki/Differentiable_function" title="Differentiable function">differentiable</a> and <a href="/wiki/Bounded_function" title="Bounded function">bounded</a>. The thresholding function has inspired building <a href="/wiki/Logic_gate" title="Logic gate">logic gates</a> referred to as threshold logic; applicable to building <a href="/wiki/Logic_circuit" class="mw-redirect" title="Logic circuit">logic circuits</a> resembling brain processing. For example, new devices such as <a href="/wiki/Memristor" title="Memristor">memristors</a> have been extensively used to develop such logic in recent times.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">&#91;1&#93;</a></sup>
</p><p>The artificial neuron transfer function should not be confused with a linear system's <a href="/wiki/Transfer_function" title="Transfer function">transfer function</a>.
</p>
<div id="toc" class="toc"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2>Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Basic_structure"><span class="tocnumber">1</span> <span class="toctext">Basic structure</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Types"><span class="tocnumber">2</span> <span class="toctext">Types</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Biological_models"><span class="tocnumber">3</span> <span class="toctext">Biological models</span></a>
<ul>
<li class="toclevel-2 tocsection-4"><a href="#Encoding"><span class="tocnumber">3.1</span> <span class="toctext">Encoding</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-5"><a href="#History"><span class="tocnumber">4</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#Types_of_transfer_functions"><span class="tocnumber">5</span> <span class="toctext">Types of transfer functions</span></a>
<ul>
<li class="toclevel-2 tocsection-7"><a href="#Step_function"><span class="tocnumber">5.1</span> <span class="toctext">Step function</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="#Linear_combination"><span class="tocnumber">5.2</span> <span class="toctext">Linear combination</span></a></li>
<li class="toclevel-2 tocsection-9"><a href="#Sigmoid"><span class="tocnumber">5.3</span> <span class="toctext">Sigmoid</span></a></li>
<li class="toclevel-2 tocsection-10"><a href="#Rectifier"><span class="tocnumber">5.4</span> <span class="toctext">Rectifier</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-11"><a href="#Pseudocode_algorithm"><span class="tocnumber">6</span> <span class="toctext">Pseudocode algorithm</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="#See_also"><span class="tocnumber">7</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-13"><a href="#References"><span class="tocnumber">8</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-14"><a href="#Further_reading"><span class="tocnumber">9</span> <span class="toctext">Further reading</span></a></li>
<li class="toclevel-1 tocsection-15"><a href="#External_links"><span class="tocnumber">10</span> <span class="toctext">External links</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Basic_structure">Basic structure</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=1" title="Edit section: Basic structure">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>For a given artificial neuron, let there be <i>m</i>&#160;+&#160;1 inputs with signals <i>x</i><sub>0</sub> through <i>x</i><sub><i>m</i></sub> and weights <i>w</i><sub>0</sub> through <i>w</i><sub><i>m</i></sub>. Usually, the <i>x</i><sub>0</sub> input is assigned the value +1, which makes it a <i>bias</i> input with <i>w</i><sub><i>k</i>0</sub>&#160;=&#160;<i>b</i><sub><i>k</i></sub>. This leaves only <i>m</i> actual inputs to the neuron: from <i>x</i><sub>1</sub> to <i>x</i><sub><i>m</i></sub>.
</p><p>The output of the <i>k</i>th neuron is:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y_{k}=\varphi \left(\sum _{j=0}^{m}w_{kj}x_{j}\right)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mi>&#x03C6;<!-- φ --></mi>
        <mrow>
          <mo>(</mo>
          <mrow>
            <munderover>
              <mo>&#x2211;<!-- ∑ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>j</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>m</mi>
              </mrow>
            </munderover>
            <msub>
              <mi>w</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>k</mi>
                <mi>j</mi>
              </mrow>
            </msub>
            <msub>
              <mi>x</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>j</mi>
              </mrow>
            </msub>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y_{k}=\varphi \left(\sum _{j=0}^{m}w_{kj}x_{j}\right)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/be21980cc9e55ea0880327b9d4797f2a0da6d06e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:20.327ex; height:7.676ex;" alt="y_{k}=\varphi \left(\sum _{{j=0}}^{m}w_{{kj}}x_{j}\right)"/></span></dd></dl>
<p>Where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \varphi }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03C6;<!-- φ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \varphi }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/33ee699558d09cf9d653f6351f9fda0b2f4aaa3e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:1.52ex; height:2.176ex;" alt="\varphi "/></span> (phi) is the transfer function.
</p><p><a href="/wiki/File:Artificial_neuron.png" class="image"><img alt="Artificial neuron.png" src="//upload.wikimedia.org/wikipedia/commons/b/b0/Artificial_neuron.png" decoding="async" width="272" height="187" data-file-width="272" data-file-height="187" /></a>
</p><p>The output is analogous to the <a href="/wiki/Axon" title="Axon">axon</a> of a biological neuron, and its value propagates to the input of the next layer, through a synapse. It may also exit the system, possibly as part of an output <a href="/wiki/Vector_(mathematics_and_physics)" title="Vector (mathematics and physics)">vector</a>.
</p><p>It has no learning process as such. Its transfer function weights are calculated and threshold value are predetermined.
</p>
<h2><span class="mw-headline" id="Types">Types</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=2" title="Edit section: Types">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Nv_network" title="Nv network">Nv network</a></div>
<p>Depending on the specific model used they may be called a <b>semi-linear unit</b>,  <b>Nv neuron</b>, <b>binary neuron</b>, <b>linear threshold function</b>, or <b>McCulloch–Pitts</b> (<b>MCP</b>) <b>neuron</b>.
</p><p>Simple artificial neurons, such as the McCulloch–Pitts model, are sometimes described as "caricature models", since they are intended to reflect one or more neurophysiological observations, but without regard to realism.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup>
</p>
<table class="box-Expand_section plainlinks metadata ambox mbox-small-left ambox-content" role="presentation"><tbody><tr><td class="mbox-image"><a href="/wiki/File:Wiki_letter_w_cropped.svg" class="image"><img alt="[icon]" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/20px-Wiki_letter_w_cropped.svg.png" decoding="async" width="20" height="14" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/30px-Wiki_letter_w_cropped.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png 2x" data-file-width="44" data-file-height="31" /></a></td><td class="mbox-text"><div class="mbox-text-span">This section <b>needs expansion</b>. <small>You can help by <a class="external text" href="//en.wikipedia.org/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=">adding to it</a>.</small>  <small class="date-container"><i>(<span class="date">May 2017</span>)</i></small></div></td></tr></tbody></table>
<h2><span class="mw-headline" id="Biological_models">Biological models</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=3" title="Edit section: Biological models">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Biological_neuron_models" class="mw-redirect" title="Biological neuron models">Biological neuron models</a></div>
<div class="thumb tright"><div class="thumbinner" style="width:392px;"><a href="/wiki/File:Neuron3.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/4/44/Neuron3.png" decoding="async" width="390" height="205" class="thumbimage" data-file-width="390" data-file-height="205" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Neuron3.png" class="internal" title="Enlarge"></a></div>Neuron and myelinated axon, with signal flow from inputs at dendrites to outputs at axon terminals</div></div></div>
<p>Artificial neurons are designed to mimic aspects of their biological counterparts.
</p>
<ul><li><i><a href="/wiki/Dendrites" class="mw-redirect" title="Dendrites">Dendrites</a></i> – In a biological neuron, the dendrites act as the input vector. These dendrites allow the cell to receive signals from a large (&gt;1000) number of neighboring neurons. As in the above mathematical treatment, each dendrite is able to perform "multiplication" by that dendrite's "weight value." The multiplication is accomplished by increasing or decreasing the ratio of synaptic neurotransmitters to signal chemicals introduced into the dendrite in response to the synaptic neurotransmitter. A negative multiplication effect can be achieved by transmitting signal inhibitors (i.e. oppositely charged ions) along the dendrite in response to the reception of synaptic neurotransmitters.</li>
<li><i><a href="/wiki/Soma_(biology)" title="Soma (biology)">Soma</a></i> – In a biological neuron, the soma acts as the summation function, seen in the above mathematical description. As positive and negative signals (exciting and inhibiting, respectively) arrive in the soma from the dendrites, the positive and negative ions are effectively added in summation, by simple virtue of being mixed together in the solution inside the cell's body.</li>
<li><i><a href="/wiki/Axon" title="Axon">Axon</a></i> – The axon gets its signal from the summation behavior which occurs inside the soma. The opening to the axon essentially samples the electrical potential of the solution inside the soma. Once the soma reaches a certain potential, the axon will transmit an all-in signal pulse down its length. In this regard, the axon behaves as the ability for us to connect our artificial neuron to other artificial neurons.</li></ul>
<p>Unlike most artificial neurons, however, biological neurons fire in discrete pulses. Each time the electrical potential inside the soma reaches a certain threshold, a pulse is transmitted down the axon. This pulsing can be translated into continuous values. The rate (activations per second, etc.) at which an axon fires converts directly into the rate at which neighboring cells get signal ions introduced into them. The faster a biological neuron fires, the faster nearby neurons accumulate electrical potential (or lose electrical potential, depending on the "weighting" of the dendrite that connects to the neuron that fired). It is this conversion that allows computer scientists and mathematicians to simulate biological neural networks using artificial neurons which can output distinct values (often from −1 to 1).
</p>
<h3><span class="mw-headline" id="Encoding">Encoding</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=4" title="Edit section: Encoding">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Research has shown that <a href="/wiki/Unary_coding" title="Unary coding">unary coding</a> is used in the neural circuits responsible for <a href="/wiki/Birdsong" class="mw-redirect" title="Birdsong">birdsong</a> production.<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup><sup id="cite_ref-4" class="reference"><a href="#cite_note-4">&#91;4&#93;</a></sup> The use of unary in biological networks is presumably due to the inherent simplicity of the coding. Another contributing factor could be that unary coding provides a certain degree of error correction.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">&#91;5&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=5" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The first artificial neuron was the Threshold Logic Unit (TLU), or Linear Threshold Unit,<sup id="cite_ref-Anthony2001_6-0" class="reference"><a href="#cite_note-Anthony2001-6">&#91;6&#93;</a></sup> first proposed by <a href="/wiki/Warren_McCulloch" class="mw-redirect" title="Warren McCulloch">Warren McCulloch</a> and <a href="/wiki/Walter_Pitts" title="Walter Pitts">Walter Pitts</a> in 1943. The model was specifically targeted as a computational model of the "nerve net" in the brain.<sup id="cite_ref-Aggarwal2014_7-0" class="reference"><a href="#cite_note-Aggarwal2014-7">&#91;7&#93;</a></sup> As a transfer function, it employed a threshold, equivalent to using the <a href="/wiki/Heaviside_step_function" title="Heaviside step function">Heaviside step function</a>. Initially, only a simple model was considered, with binary inputs and outputs, some restrictions on the possible weights, and a more flexible threshold value. Since the beginning it was already noticed that any <a href="/wiki/Boolean_function" title="Boolean function">boolean function</a> could be implemented by networks of such devices, what is easily seen from the fact that one can implement the AND and OR functions, and use them in the <a href="/wiki/Disjunctive_normal_form" title="Disjunctive normal form">disjunctive</a> or the <a href="/wiki/Conjunctive_normal_form" title="Conjunctive normal form">conjunctive normal form</a>.
Researchers also soon realized that cyclic networks, with <a href="/wiki/Feedback" title="Feedback">feedbacks</a> through neurons, could define dynamical systems with memory, but most of the research concentrated (and still does) on strictly <a href="/wiki/Feed-forward_network" class="mw-redirect" title="Feed-forward network">feed-forward networks</a> because of the smaller difficulty they present.
</p><p>One important and pioneering artificial neural network that used the linear threshold function was the <a href="/wiki/Perceptron" title="Perceptron">perceptron</a>, developed by <a href="/wiki/Frank_Rosenblatt" title="Frank Rosenblatt">Frank Rosenblatt</a>. This model already considered more flexible weight values in the neurons, and was used in machines with adaptive capabilities. The representation of the threshold values as a bias term was introduced by <a href="/wiki/Bernard_Widrow" title="Bernard Widrow">Bernard Widrow</a> in 1960 – see <a href="/wiki/ADALINE" title="ADALINE">ADALINE</a>.
</p><p>In the late 1980s, when research on neural networks regained strength, neurons with more continuous shapes started to be considered. The possibility of differentiating the activation function allows the direct use of the <a href="/wiki/Gradient_descent" title="Gradient descent">gradient descent</a> and other optimization algorithms for the adjustment of the weights. Neural networks also started to be used as a general <a href="/wiki/Function_approximation" title="Function approximation">function approximation</a> model. The best known training algorithm called <a href="/wiki/Backpropagation" title="Backpropagation">backpropagation</a> has been rediscovered several times but its first development goes back to the work of <a href="/wiki/Paul_Werbos" title="Paul Werbos">Paul Werbos</a>.<sup id="cite_ref-8" class="reference"><a href="#cite_note-8">&#91;8&#93;</a></sup><sup id="cite_ref-9" class="reference"><a href="#cite_note-9">&#91;9&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Types_of_transfer_functions">Types of transfer functions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=6" title="Edit section: Types of transfer functions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table class="plainlinks metadata ambox ambox-move" role="presentation"><tbody><tr><td class="mbox-image"><div style="width:52px"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Split-arrows.svg/50px-Split-arrows.svg.png" decoding="async" width="50" height="17" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Split-arrows.svg/75px-Split-arrows.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Split-arrows.svg/100px-Split-arrows.svg.png 2x" data-file-width="300" data-file-height="100" /></div></td><td class="mbox-text"><div class="mbox-text-span">It has been suggested that this section be <a href="/wiki/Wikipedia:Splitting" title="Wikipedia:Splitting">split</a> out  into another article&#32;titled <i><a href="/wiki/Transfer_function" title="Transfer function">transfer function</a></i>. (<a href="/wiki/Talk:Artificial_neuron" title="Talk:Artificial neuron">Discuss</a>) <small><i>(May 2017)</i></small></div></td></tr></tbody></table>
<p>The transfer function (<a href="/wiki/Activation_function" title="Activation function">activation function</a>) of a neuron is chosen to have a number of properties which either enhance or simplify the network containing the neuron.  Crucially, for instance, any <a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">multilayer perceptron</a> using a <i>linear</i> transfer function has an equivalent single-layer network; a non-linear function is therefore necessary to gain the advantages of a multi-layer network.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (May 2018)">citation needed</span></a></i>&#93;</sup>
</p><p>Below, <i>u</i> refers in all cases to the weighted sum of all the inputs to the neuron, i.e. for <i>n</i> inputs,
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle u=\sum _{i=1}^{n}w_{i}x_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>u</mi>
        <mo>=</mo>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </munderover>
        <msub>
          <mi>w</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle u=\sum _{i=1}^{n}w_{i}x_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8773ce7afe8e89c86732f0b59beb83f41f23c832" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:12.763ex; height:6.843ex;" alt="u=\sum _{{i=1}}^{n}w_{i}x_{i}"/></span></dd></dl>
<p>where <b>w</b> is a vector of <i>synaptic weights</i> and <b>x</b> is a vector of inputs.
</p>
<h3><span class="mw-headline" id="Step_function">Step function</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=7" title="Edit section: Step function">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The output <i>y</i> of this transfer function is binary, depending on whether the input meets a specified threshold, <i>θ</i>. The "signal" is sent, i.e. the output is set to one, if the activation meets the threshold.
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y={\begin{cases}1&amp;{\text{if }}u\geq \theta \\0&amp;{\text{if }}u&lt;\theta \end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>u</mi>
                  <mo>&#x2265;<!-- ≥ --></mo>
                  <mi>&#x03B8;<!-- θ --></mi>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>0</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>u</mi>
                  <mo>&lt;</mo>
                  <mi>&#x03B8;<!-- θ --></mi>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y={\begin{cases}1&amp;{\text{if }}u\geq \theta \\0&amp;{\text{if }}u&lt;\theta \end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9dd1436c7b0c1fa2ad911c56f237fd23d925cca3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:17.692ex; height:6.176ex;" alt="y={\begin{cases}1&amp;{\text{if }}u\geq \theta \\0&amp;{\text{if }}u&lt;\theta \end{cases}}"/></span></dd></dl>
<p>This function is used in <a href="/wiki/Perceptron" title="Perceptron">perceptrons</a> and often shows up in many other models. It performs a division of the <a href="/wiki/Vector_space" title="Vector space">space</a> of inputs by a <a href="/wiki/Hyperplane" title="Hyperplane">hyperplane</a>. It is specially useful in the last layer of a network intended to perform binary classification of the inputs. It can be approximated from other sigmoidal functions by assigning large values to the weights.
</p>
<h3><span class="mw-headline" id="Linear_combination">Linear combination</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=8" title="Edit section: Linear combination">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>In this case, the output unit is simply the weighted sum of its inputs plus a <i>bias</i> term. A number of such linear neurons perform a linear transformation of the input vector. This is usually more useful in the first layers of a network. A number of analysis tools exist based on linear models, such as <a href="/wiki/Harmonic_analysis" title="Harmonic analysis">harmonic analysis</a>, and they can all be used in neural networks with this linear neuron. The bias term allows us to make <a href="/wiki/Homogeneous_coordinates" title="Homogeneous coordinates">affine transformations</a> to the data.
</p><p>See: <a href="/wiki/Linear_transformation" class="mw-redirect" title="Linear transformation">Linear transformation</a>, <a href="/wiki/Harmonic_analysis" title="Harmonic analysis">Harmonic analysis</a>, <a href="/wiki/Linear_filter" title="Linear filter">Linear filter</a>, <a href="/wiki/Wavelet" title="Wavelet">Wavelet</a>, <a href="/wiki/Principal_component_analysis" title="Principal component analysis">Principal component analysis</a>, <a href="/wiki/Independent_component_analysis" title="Independent component analysis">Independent component analysis</a>, <a href="/wiki/Deconvolution" title="Deconvolution">Deconvolution</a>.
</p>
<h3><span class="mw-headline" id="Sigmoid">Sigmoid</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=9" title="Edit section: Sigmoid">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/Sigmoid_function" title="Sigmoid function">Sigmoid function</a></div>
<p>A fairly simple non-linear function, the <a href="/wiki/Sigmoid_function" title="Sigmoid function">sigmoid function</a> such as the logistic function also has an easily calculated derivative, which can be important when calculating the weight updates in the network. It thus makes the network more easily manipulable mathematically, and was attractive to early computer scientists who needed to minimize the computational load of their simulations. It was previously commonly seen in <a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">multilayer perceptrons</a>. However, recent work has shown sigmoid neurons to be less effective than <a href="/wiki/Rectifier_(neural_networks)" title="Rectifier (neural networks)">rectified linear</a> neurons. The reason is that the gradients computed by the <a href="/wiki/Backpropagation" title="Backpropagation">backpropagation</a> algorithm tend to diminish towards zero as activations propagate through layers of sigmoidal neurons, making it difficult to optimize neural networks using multiple layers of sigmoidal neurons.
</p>
<h3><span class="mw-headline" id="Rectifier">Rectifier</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=10" title="Edit section: Rectifier">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/Rectifier_(neural_networks)" title="Rectifier (neural networks)">Rectifier (neural networks)</a></div>
<p>In the context of <a href="/wiki/Artificial_neural_network" title="Artificial neural network">artificial neural networks</a>, the <b>rectifier</b> is an <a href="/wiki/Activation_function" title="Activation function">activation function</a> defined as the positive part of its argument:
</p><p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f(x)=x^{+}=\max(0,x)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <msup>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>+</mo>
          </mrow>
        </msup>
        <mo>=</mo>
        <mo movablelimits="true" form="prefix">max</mo>
        <mo stretchy="false">(</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f(x)=x^{+}=\max(0,x)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bb2c32931fad595832c8e66f2f73760ebcbc0096" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:23.116ex; height:3.009ex;" alt="{\displaystyle f(x)=x^{+}=\max(0,x)}"/></span>,
</p><p>where <i>x</i> is the input to a neuron. This is also known as a <a href="/wiki/Ramp_function" title="Ramp function">ramp function</a> and is analogous to <a href="/wiki/Half-wave_rectification" class="mw-redirect" title="Half-wave rectification">half-wave rectification</a> in electrical engineering. 
This <a href="/wiki/Activation_function" title="Activation function">activation function</a> was first introduced to a dynamical network by Hahnloser et al. in a 2000 paper in Nature<sup id="cite_ref-Hahnloser2000_10-0" class="reference"><a href="#cite_note-Hahnloser2000-10">&#91;10&#93;</a></sup> with strong <a href="/wiki/Biological" class="mw-redirect" title="Biological">biological</a> motivations and mathematical justifications.<sup id="cite_ref-Hahnloser2001_11-0" class="reference"><a href="#cite_note-Hahnloser2001-11">&#91;11&#93;</a></sup> It has been demonstrated for the first time in 2011 to enable better training of deeper networks,<sup id="cite_ref-glorot2011_12-0" class="reference"><a href="#cite_note-glorot2011-12">&#91;12&#93;</a></sup> compared to the widely used activation functions prior to 2011, i.e., the <a href="/wiki/Logistic_function" title="Logistic function">logistic sigmoid</a> (which is inspired by <a href="/wiki/Probability_theory" title="Probability theory">probability theory</a>; see <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>) and its more practical<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">&#91;13&#93;</a></sup> counterpart, the <a href="/wiki/Hyperbolic_tangent" class="mw-redirect" title="Hyperbolic tangent">hyperbolic tangent</a>.
</p>
<h2><span class="mw-headline" id="Pseudocode_algorithm">Pseudocode algorithm</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=11" title="Edit section: Pseudocode algorithm">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table class="plainlinks metadata ambox ambox-move" role="presentation"><tbody><tr><td class="mbox-image"><div style="width:52px"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Split-arrows.svg/50px-Split-arrows.svg.png" decoding="async" width="50" height="17" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Split-arrows.svg/75px-Split-arrows.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Split-arrows.svg/100px-Split-arrows.svg.png 2x" data-file-width="300" data-file-height="100" /></div></td><td class="mbox-text"><div class="mbox-text-span">It has been suggested that this section be <a href="/wiki/Wikipedia:Splitting" title="Wikipedia:Splitting">split</a> out  into another article&#32;titled <i><a href="/wiki/Threshold_Logic_Unit" class="mw-redirect" title="Threshold Logic Unit">Threshold Logic Unit</a></i>. (<a href="/wiki/Talk:Artificial_neuron" title="Talk:Artificial neuron">Discuss</a>) <small><i>(May 2017)</i></small></div></td></tr></tbody></table>
<p>The following is a simple <a href="/wiki/Pseudocode" title="Pseudocode">pseudocode</a> implementation of a single TLU which takes <a href="/wiki/Boolean_data_type" title="Boolean data type">boolean</a> inputs (true or false), and returns a single boolean output when activated. An <a href="/wiki/Object_oriented" class="mw-redirect" title="Object oriented">object-oriented</a> model is used. No method of training is defined, since several exist. If a purely functional model were used, the class TLU below would be replaced with a function TLU with input parameters threshold, weights, and inputs that returned a boolean value.
</p>
<pre> <b>class</b> TLU <b>defined as:</b>
  <b>data member</b> threshold <b>:</b> number
  <b>data member</b> weights <b>: list of</b> numbers <b>of size</b> X
  <b>function member</b> fire( inputs <b>: list of</b> booleans <b>of size</b> X ) <b>:</b> boolean <b>defined as:</b>
   <b>variable</b> T <b>:</b> number
   T <b>←</b> 0
   <b>for each</b> i <b>in</b> 1 <b>to</b> X <b>:</b>
    <b>if</b> inputs(i) <b>is</b> true <b>:</b>
     T <b>←</b> T + weights(i)
    <b>end if</b>
   <b>end for each</b>
   <b>if</b> T &gt; threshold <b>:</b>
    <b>return</b> true
   <b>else:</b>
    <b>return</b> false
   <b>end if</b>
  <b>end function</b>
 <b>end class</b>
</pre>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=12" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Binding_neuron" title="Binding neuron">Binding neuron</a></li>
<li><a href="/wiki/Connectionism" title="Connectionism">Connectionism</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=13" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><cite class="citation journal">Maan, A. K.; Jayadevi, D. A.; James, A. P. (1 January 2016). "A Survey of Memristive Threshold Logic Circuits". <i>IEEE Transactions on Neural Networks and Learning Systems</i>. <b>PP</b> (99): 1734–1746. <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1604.07121">1604.07121</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1109%2FTNNLS.2016.2547842">10.1109/TNNLS.2016.2547842</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/2162-237X">2162-237X</a>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/27164608">27164608</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Neural+Networks+and+Learning+Systems&amp;rft.atitle=A+Survey+of+Memristive+Threshold+Logic+Circuits&amp;rft.volume=PP&amp;rft.issue=99&amp;rft.pages=1734-1746&amp;rft.date=2016-01-01&amp;rft_id=info%3Aarxiv%2F1604.07121&amp;rft.issn=2162-237X&amp;rft_id=info%3Apmid%2F27164608&amp;rft_id=info%3Adoi%2F10.1109%2FTNNLS.2016.2547842&amp;rft.aulast=Maan&amp;rft.aufirst=A.+K.&amp;rft.au=Jayadevi%2C+D.+A.&amp;rft.au=James%2C+A.+P.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+neuron" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r886058088">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text">
<cite class="citation book">F. C. Hoppensteadt and E. M. Izhikevich (1997). <i>Weakly connected neural networks</i>. Springer. p.&#160;4. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-387-94948-2" title="Special:BookSources/978-0-387-94948-2">978-0-387-94948-2</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Weakly+connected+neural+networks&amp;rft.pages=4&amp;rft.pub=Springer&amp;rft.date=1997&amp;rft.isbn=978-0-387-94948-2&amp;rft.au=F.+C.+Hoppensteadt+and+E.+M.+Izhikevich&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+neuron" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><cite class="citation book">Squire, L.; Albright, T.; Bloom, F.; Gage, F.; Spitzer, N., eds. (October 2007). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20150412190625/https://clm.utexas.edu/fietelab/Papers/birdsong_review_topost.pdf"><i>Neural network models of birdsong production, learning, and coding</i></a> <span class="cs1-format">(PDF)</span>. New Encyclopedia of Neuroscience: Elservier. Archived from <a rel="nofollow" class="external text" href="https://clm.utexas.edu/fietelab/Papers/birdsong_review_topost.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2015-04-12<span class="reference-accessdate">. Retrieved <span class="nowrap">12 April</span> 2015</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Neural+network+models+of+birdsong+production%2C+learning%2C+and+coding&amp;rft.place=New+Encyclopedia+of+Neuroscience&amp;rft.pub=Elservier&amp;rft.date=2007-10&amp;rft_id=https%3A%2F%2Fclm.utexas.edu%2Ffietelab%2FPapers%2Fbirdsong_review_topost.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+neuron" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text">Moore J.M. et al., "Motor pathway convergence predicts syllable repertoire size in oscine birds". <i>Proc. Natl. Acad. Sci.</i> USA 108: 16440–16445, 2011. <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/><a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/21918109">21918109</a> <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1073%2Fpnas.1102077108">10.1073/pnas.1102077108</a></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><cite class="citation arxiv">Potluri, Pushpa Sree (26 November 2014). "Error Correction Capacity of Unary Coding". <a href="/wiki/ArXiv" title="ArXiv">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1411.7406">1411.7406</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.IT">cs.IT</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Error+Correction+Capacity+of+Unary+Coding&amp;rft.date=2014-11-26&amp;rft_id=info%3Aarxiv%2F1411.7406&amp;rft.aulast=Potluri&amp;rft.aufirst=Pushpa+Sree&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+neuron" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-Anthony2001-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-Anthony2001_6-0">^</a></b></span> <span class="reference-text"><cite class="citation book">Martin Anthony (January 2001). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=qOy4yLBqhFcC&amp;pg=PA3"><i>Discrete Mathematics of Neural Networks: Selected Topics</i></a>. SIAM. pp.&#160;3–. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-89871-480-7" title="Special:BookSources/978-0-89871-480-7">978-0-89871-480-7</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Discrete+Mathematics+of+Neural+Networks%3A+Selected+Topics&amp;rft.pages=3-&amp;rft.pub=SIAM&amp;rft.date=2001-01&amp;rft.isbn=978-0-89871-480-7&amp;rft.au=Martin+Anthony&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DqOy4yLBqhFcC%26pg%3DPA3&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+neuron" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-Aggarwal2014-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-Aggarwal2014_7-0">^</a></b></span> <span class="reference-text"><cite class="citation book">Charu C. Aggarwal (25 July 2014). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=gJhBBAAAQBAJ&amp;pg=PA209"><i>Data Classification: Algorithms and Applications</i></a>. CRC Press. pp.&#160;209–. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4665-8674-1" title="Special:BookSources/978-1-4665-8674-1">978-1-4665-8674-1</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Data+Classification%3A+Algorithms+and+Applications&amp;rft.pages=209-&amp;rft.pub=CRC+Press&amp;rft.date=2014-07-25&amp;rft.isbn=978-1-4665-8674-1&amp;rft.au=Charu+C.+Aggarwal&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DgJhBBAAAQBAJ%26pg%3DPA209&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+neuron" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><a href="/wiki/Paul_Werbos" title="Paul Werbos">Paul Werbos</a>, Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences. PhD thesis, Harvard University, 1974</span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><a href="/wiki/Paul_Werbos" title="Paul Werbos">Paul Werbos</a>, Backpropagation through time: what it does and how to do it. Proceedings of the IEEE, Volume 78, Issue 10, 1550–1560, Oct 1990, doi10.1109/5.58337</span>
</li>
<li id="cite_note-Hahnloser2000-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-Hahnloser2000_10-0">^</a></b></span> <span class="reference-text"><cite class="citation conference">R Hahnloser, R. Sarpeshkar, M A Mahowald, R. J. Douglas, H.S. Seung (2000). <i>Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit</i>. <i>Nature</i>. <b>405</b>. pp.&#160;947–951.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=conference&amp;rft.jtitle=Nature&amp;rft.atitle=Digital+selection+and+analogue+amplification+coexist+in+a+cortex-inspired+silicon+circuit&amp;rft.volume=405&amp;rft.pages=947-951&amp;rft.date=2000&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+neuron" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: Uses authors parameter (<a href="/wiki/Category:CS1_maint:_Uses_authors_parameter" title="Category:CS1 maint: Uses authors parameter">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-Hahnloser2001-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-Hahnloser2001_11-0">^</a></b></span> <span class="reference-text"><cite class="citation conference">R Hahnloser, H.S. Seung (2001). <i>Permitted and Forbidden Sets in Symmetric Threshold-Linear Networks</i>. NIPS 2001.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Permitted+and+Forbidden+Sets+in+Symmetric+Threshold-Linear+Networks&amp;rft.date=2001&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+neuron" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: Uses authors parameter (<a href="/wiki/Category:CS1_maint:_Uses_authors_parameter" title="Category:CS1 maint: Uses authors parameter">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-glorot2011-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-glorot2011_12-0">^</a></b></span> <span class="reference-text"><cite class="citation conference">Xavier Glorot, Antoine Bordes and <a href="/wiki/Yoshua_Bengio" title="Yoshua Bengio">Yoshua Bengio</a> (2011). <a rel="nofollow" class="external text" href="http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf"><i>Deep sparse rectifier neural networks</i></a> <span class="cs1-format">(PDF)</span>. AISTATS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Deep+sparse+rectifier+neural+networks&amp;rft.date=2011&amp;rft_id=http%3A%2F%2Fjmlr.org%2Fproceedings%2Fpapers%2Fv15%2Fglorot11a%2Fglorot11a.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+neuron" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: Uses authors parameter (<a href="/wiki/Category:CS1_maint:_Uses_authors_parameter" title="Category:CS1 maint: Uses authors parameter">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><cite class="citation encyclopaedia"><a href="/wiki/Yann_LeCun" title="Yann LeCun">Yann LeCun</a>, <a href="/wiki/Leon_Bottou" class="mw-redirect" title="Leon Bottou">Leon Bottou</a>, Genevieve B. Orr and <a href="/wiki/Klaus-Robert_M%C3%BCller" title="Klaus-Robert Müller">Klaus-Robert Müller</a> (1998). <a rel="nofollow" class="external text" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">"Efficient BackProp"</a> <span class="cs1-format">(PDF)</span>.  In G. Orr and K. Müller. <i>Neural Networks: Tricks of the Trade</i>. Springer.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Efficient+BackProp&amp;rft.btitle=Neural+Networks%3A+Tricks+of+the+Trade&amp;rft.pub=Springer&amp;rft.date=1998&amp;rft_id=http%3A%2F%2Fyann.lecun.com%2Fexdb%2Fpublis%2Fpdf%2Flecun-98b.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AArtificial+neuron" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: Uses authors parameter (<a href="/wiki/Category:CS1_maint:_Uses_authors_parameter" title="Category:CS1 maint: Uses authors parameter">link</a>) CS1 maint: Uses editors parameter (<a href="/wiki/Category:CS1_maint:_Uses_editors_parameter" title="Category:CS1 maint: Uses editors parameter">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>
</li>
</ol></div></div>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=14" title="Edit section: Further reading">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r886047268">.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{list-style-type:none;margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li,.mw-parser-output .refbegin-hanging-indents>dl>dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output .refbegin-100{font-size:100%}</style><div class="refbegin" style="">
<ul><li><a href="/wiki/Warren_McCulloch" class="mw-redirect" title="Warren McCulloch">McCulloch, W</a>. and <a href="/wiki/Walter_Pitts" title="Walter Pitts">Pitts, W</a>. (1943). <i>A logical calculus of the ideas immanent in nervous activity.</i> Bulletin of Mathematical Biophysics, 5:115–133. <a rel="nofollow" class="external autonumber" href="https://link.springer.com/article/10.1007%2FBF02478259">[1]</a></li>
<li>A.S. Samardak, A. Nogaret, N. B. Janson, A. G. Balanov, I. Farrer and D. A. Ritchie. "Noise-Controlled Signal Transmission in a Multithread Semiconductor Neuron" // Phys. Rev. Lett. 102 (2009) 226802, <a rel="nofollow" class="external autonumber" href="https://archive.is/20120713205438/http://prl.aps.org/abstract/PRL/v102/i22/e226802">[2]</a></li></ul>
</div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit&amp;section=15" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a rel="nofollow" class="external text" href="https://www.youtube.com/watch?v=NhTZnnJJP64">Artifical&#32;&#91;<i>sic</i>&#93; neuron mimicks function of human cells</a></li>
<li><a rel="nofollow" class="external text" href="http://www.mind.ilstu.edu/curriculum/modOverview.php?modGUI=212">McCulloch-Pitts Neurons (Overview)</a></li></ul>

<!-- 
NewPP limit report
Parsed by mw1253
Cached time: 20190304012637
Cache expiry: 2592000
Dynamic content: false
CPU time usage: 0.412 seconds
Real time usage: 0.613 seconds
Preprocessor visited node count: 1679/1000000
Preprocessor generated node count: 0/1500000
Post‐expand include size: 35060/2097152 bytes
Template argument size: 1951/2097152 bytes
Highest expansion depth: 15/40
Expensive parser function count: 7/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 34471/5000000 bytes
Number of Wikibase entities loaded: 3/400
Lua time usage: 0.201/10.000 seconds
Lua memory usage: 4.14 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  501.706      1 -total
 49.41%  247.876      1 Template:Reflist
 24.50%  122.939      1 Template:Cite_journal
 18.47%   92.678      1 Template:Clarify
 14.57%   73.106      1 Template:Fix-span
 10.95%   54.914      2 Template:Split_section
  9.68%   48.559      2 Template:Split_portions
  9.13%   45.792      4 Template:Category_handler
  6.55%   32.843      3 Template:Ambox
  5.54%   27.797      2 Template:Delink
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:349771-0!canonical!math=5 and timestamp 20190304012636 and revision id 885171186
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>					<div class="printfooter">
						Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Artificial_neuron&amp;oldid=885171186">https://en.wikipedia.org/w/index.php?title=Artificial_neuron&amp;oldid=885171186</a>"					</div>
				<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Artificial_neural_networks" title="Category:Artificial neural networks">Artificial neural networks</a></li><li><a href="/wiki/Category:American_inventions" title="Category:American inventions">American inventions</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:CS1_maint:_Uses_authors_parameter" title="Category:CS1 maint: Uses authors parameter">CS1 maint: Uses authors parameter</a></li><li><a href="/wiki/Category:CS1_maint:_Uses_editors_parameter" title="Category:CS1 maint: Uses editors parameter">CS1 maint: Uses editors parameter</a></li><li><a href="/wiki/Category:Wikipedia_articles_needing_clarification_from_May_2017" title="Category:Wikipedia articles needing clarification from May 2017">Wikipedia articles needing clarification from May 2017</a></li><li><a href="/wiki/Category:Articles_to_be_expanded_from_May_2017" title="Category:Articles to be expanded from May 2017">Articles to be expanded from May 2017</a></li><li><a href="/wiki/Category:All_articles_to_be_expanded" title="Category:All articles to be expanded">All articles to be expanded</a></li><li><a href="/wiki/Category:Articles_using_small_message_boxes" title="Category:Articles using small message boxes">Articles using small message boxes</a></li><li><a href="/wiki/Category:Articles_to_be_split_from_May_2017" title="Category:Articles to be split from May 2017">Articles to be split from May 2017</a></li><li><a href="/wiki/Category:All_articles_to_be_split" title="Category:All articles to be split">All articles to be split</a></li><li><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_May_2018" title="Category:Articles with unsourced statements from May 2018">Articles with unsourced statements from May 2018</a></li></ul></div></div>				<div class="visualClear"></div>
							</div>
		</div>
		<div id="mw-navigation">
			<h2>Navigation menu</h2>
			<div id="mw-head">
									<div id="p-personal" role="navigation" aria-labelledby="p-personal-label">
						<h3 id="p-personal-label">Personal tools</h3>
						<ul>
							<li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Artificial+neuron" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Artificial+neuron" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>						</ul>
					</div>
									<div id="left-navigation">
										<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
						<h3 id="p-namespaces-label">Namespaces</h3>
						<ul>
							<li id="ca-nstab-main" class="selected"><span><a href="/wiki/Artificial_neuron" title="View the content page [c]" accesskey="c">Article</a></span></li><li id="ca-talk"><span><a href="/wiki/Talk:Artificial_neuron" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></span></li>						</ul>
					</div>
										<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
												<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />
						<h3 id="p-variants-label">
							<span>Variants</span>
						</h3>
						<ul class="menu">
													</ul>
					</div>
									</div>
				<div id="right-navigation">
										<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
						<h3 id="p-views-label">Views</h3>
						<ul>
							<li id="ca-view" class="collapsible selected"><span><a href="/wiki/Artificial_neuron">Read</a></span></li><li id="ca-edit" class="collapsible"><span><a href="/w/index.php?title=Artificial_neuron&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></span></li><li id="ca-history" class="collapsible"><span><a href="/w/index.php?title=Artificial_neuron&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></span></li>						</ul>
					</div>
										<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
						<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
						<h3 id="p-cactions-label"><span>More</span></h3>
						<ul class="menu">
													</ul>
					</div>
										<div id="p-search" role="search">
						<h3>
							<label for="searchInput">Search</label>
						</h3>
						<form action="/w/index.php" id="searchform">
							<div id="simpleSearch">
								<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/><input type="hidden" value="Special:Search" name="title"/><input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>							</div>
						</form>
					</div>
									</div>
			</div>
			<div id="mw-panel">
				<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a></div>
						<div class="portal" role="navigation" id="p-navigation" aria-labelledby="p-navigation-label">
			<h3 id="p-navigation-label">Navigation</h3>
			<div class="body">
								<ul>
					<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-interaction" aria-labelledby="p-interaction-label">
			<h3 id="p-interaction-label">Interaction</h3>
			<div class="body">
								<ul>
					<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-tb" aria-labelledby="p-tb-label">
			<h3 id="p-tb-label">Tools</h3>
			<div class="body">
								<ul>
					<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Artificial_neuron" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Artificial_neuron" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Artificial_neuron&amp;oldid=885171186" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Artificial_neuron&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q177058" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Artificial_neuron&amp;id=885171186" title="Information on how to cite this page">Cite this page</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-coll-print_export" aria-labelledby="p-coll-print_export-label">
			<h3 id="p-coll-print_export-label">Print/export</h3>
			<div class="body">
								<ul>
					<li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Artificial+neuron">Create a book</a></li><li id="coll-download-as-rdf2latex"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Artificial+neuron&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Artificial_neuron&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>				</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id="p-lang" aria-labelledby="p-lang-label">
			<h3 id="p-lang-label">Languages</h3>
			<div class="body">
								<ul>
					<li class="interlanguage-link interwiki-ar"><a href="https://ar.wikipedia.org/wiki/%D8%B9%D8%B5%D8%A8_%D8%A7%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%D9%8A" title="عصب اصطناعي – Arabic" lang="ar" hreflang="ar" class="interlanguage-link-target">العربية</a></li><li class="interlanguage-link interwiki-az"><a href="https://az.wikipedia.org/wiki/S%C3%BCni_neyron" title="Süni neyron – Azerbaijani" lang="az" hreflang="az" class="interlanguage-link-target">Azərbaycanca</a></li><li class="interlanguage-link interwiki-de badge-Q17437798 badge-goodarticle" title="good article"><a href="https://de.wikipedia.org/wiki/K%C3%BCnstliches_Neuron" title="Künstliches Neuron – German" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-et"><a href="https://et.wikipedia.org/wiki/Tehisneuron" title="Tehisneuron – Estonian" lang="et" hreflang="et" class="interlanguage-link-target">Eesti</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Neurone_formel" title="Neurone formel – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B3%B5_%EB%89%B4%EB%9F%B0" title="인공 뉴런 – Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">한국어</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%B5%8C" title="人工神経 – Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target">日本語</a></li><li class="interlanguage-link interwiki-pt"><a href="https://pt.wikipedia.org/wiki/Neur%C3%B4nio_artificial" title="Neurônio artificial – Portuguese" lang="pt" hreflang="pt" class="interlanguage-link-target">Português</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%98%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D1%8B%D0%B9_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD" title="Искусственный нейрон – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-ta"><a href="https://ta.wikipedia.org/wiki/%E0%AE%9A%E0%AF%86%E0%AE%AF%E0%AE%B1%E0%AF%8D%E0%AE%95%E0%AF%88_%E0%AE%A8%E0%AE%B0%E0%AE%AE%E0%AF%8D%E0%AE%AA%E0%AE%A3%E0%AF%81" title="செயற்கை நரம்பணு – Tamil" lang="ta" hreflang="ta" class="interlanguage-link-target">தமிழ்</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%A8%D1%82%D1%83%D1%87%D0%BD%D0%B8%D0%B9_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD" title="Штучний нейрон – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li>				</ul>
				<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q177058#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>			</div>
		</div>
				</div>
		</div>
				<div id="footer" role="contentinfo">
						<ul id="footer-info">
								<li id="footer-info-lastmod"> This page was last edited on 26 February 2019, at 11:47<span class="anonymous-show">&#160;(UTC)</span>.</li>
								<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
							</ul>
						<ul id="footer-places">
								<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
								<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
								<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
								<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
								<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
								<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
								<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Artificial_neuron&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
							</ul>
										<ul id="footer-icons" class="noprint">
										<li id="footer-copyrightico">
						<a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a>					</li>
										<li id="footer-poweredbyico">
						<a href="//www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a>					</li>
									</ul>
						<div style="clear: both;"></div>
		</div>
		
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.412","walltime":"0.613","ppvisitednodes":{"value":1679,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":35060,"limit":2097152},"templateargumentsize":{"value":1951,"limit":2097152},"expansiondepth":{"value":15,"limit":40},"expensivefunctioncount":{"value":7,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":34471,"limit":5000000},"entityaccesscount":{"value":3,"limit":400},"timingprofile":["100.00%  501.706      1 -total"," 49.41%  247.876      1 Template:Reflist"," 24.50%  122.939      1 Template:Cite_journal"," 18.47%   92.678      1 Template:Clarify"," 14.57%   73.106      1 Template:Fix-span"," 10.95%   54.914      2 Template:Split_section","  9.68%   48.559      2 Template:Split_portions","  9.13%   45.792      4 Template:Category_handler","  6.55%   32.843      3 Template:Ambox","  5.54%   27.797      2 Template:Delink"]},"scribunto":{"limitreport-timeusage":{"value":"0.201","limit":"10.000"},"limitreport-memusage":{"value":4344885,"limit":52428800}},"cachereport":{"origin":"mw1253","timestamp":"20190304012637","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Artificial neuron","url":"https:\/\/en.wikipedia.org\/wiki\/Artificial_neuron","sameAs":"http:\/\/www.wikidata.org\/entity\/Q177058","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q177058","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2003-10-25T22:32:25Z","dateModified":"2019-02-26T11:47:07Z","headline":"mathematical function conceived as a crude model"}</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":131,"wgHostname":"mw1274"});});</script>
	</body>
</html>
